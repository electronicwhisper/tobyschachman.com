<html>
<head>

<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />

<link href="http://code.ionicframework.com/ionicons/1.5.2/css/ionicons.min.css" rel="stylesheet" type="text/css" />
<link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,700,200italic,300italic,400italic,700italic" rel="stylesheet" type="text/css" />
<link rel="icon" type="image/png" href="/assets/favicon.png">

<link href="/assets/page.css" rel="stylesheet" type="text/css" />

<title>Shadershop</title>
</head>

<body class="ThemeLight">

<div class="Centered"><div class="Title">Shadershop</div>
<div class="Date">December 2014</div>

<!-- Shadershop


abs(x - 1.0) * 2.0

cos(x)
cos(x * 6.28)
cos(x * 6.28) + x

mod(x, 2.) - 1.
abs(mod(x, 2.) - 1.)



# Future Work

More visualizations
Time
More abstractions: loops and conditionals, higher-order functions
Targets: mandelbrot fractal, ray tracer
Showing composition -->




<p>The rest of this document is structured as follows: I give a tour through past prototypes of Shadershop with an emphasis on features that were left out. Then I discuss future directions for direct manipulation in shader-like programming. I close with notes on the development process of Shadershop, and try to distill some &#x201C;lessons learned&#x201D; that may be helpful to others developing similar interfaces.</p>
<p>But first, a bonus video&#x2026;</p>
<h1 id="is-it-perlin-noise-">Is it Perlin Noise?</h1>
<p>Not quite. The noise shown above is called &#x201C;value noise&#x201D; and is a different formulation than Ken Perlin&#x2019;s original formulation of &#x201C;gradient noise&#x201D;. Here&#x2019;s the difference:</p>
<h1 id="evolution">Evolution</h1>
<h2 id="origins">Origins</h2>
<p>Shadershop evolved from two prototypes I made for the <a href="http://pixelshaders.com/">Pixel Shaders</a> project.</p>
<p>The first was an interactive visualization that let you explore a mathematical expression by breaking it down into pieces. In shaders you often come across magical one-liners that perform some signal transformation, for example <code>abs(mod(x, 2.) - 1.)</code> which makes a signal &#x201C;bounce&#x201D; between 0 and 1. Like a long sentence with unfamiliar words, these can be tricky to parse for beginners. But experienced programmers know to build understanding in parts: figure out what each subexpression does and then figure out how they combine to make the whole expression. You keep breaking the problem down into subproblems until your subproblems are small enough that you can wrap your mind around them. Then build back up again.</p>
<div class="VideoEmbed" data-src="http://player.vimeo.com/video/112119838" data-aspect="1.776"></div>

<p>I tried to capture this experience through this cartesian graph visualization. The expression in question is broken down into subexpressions exactly as the computer would parse it, as in an abstract syntax tree. You can then hover any subexpression to see it, and as you move &#x201C;up&#x201D; the tree, you can see how each modification to the expression transforms the graph.</p>
<p>The goal is to get the beginner programmer thinking in terms of transformations, using functions to sculpt signals. I thought it might be neat to augment a visualization like this with a manipulation interface so that you could sculpt the signal by applying functions to it, like applying filters to an image in Photoshop.</p>
<p>I had the opportunity to try this during my Eyebeam/Mozilla fellowship for Pixel Shaders. <a href="http://eyebeam.org/">Eyebeam</a> is very much embedded in the Art world and as such the venue for expression is the gallery or exhibition. Typically to learn programming requires sitting and concentrating alone for hours. How do you convey the experience of shader programming to gallery visitors who might poke at your installation for thirty seconds and want to hang out with their friends while doing it?</p>
<p>Refractor was my attempt to satisfy this design constraint.</p>
<p>[Refractor video]</p>
<p>Visitors start with a base image (or live webcam feed) and apply layers of filters on top. Each filter is just a built-in GLSL primitive (abs, sin, etc.). Each layer can be given an individual affine transformation. I knew from Recursive Drawing that specifying affine transformations through direct manipulation (and especially multitouch) is very natural.</p>
<p>There&#x2019;s no code to type and every thing you can do has immediate visual feedback. Though something I noticed is that visitors would sometimes hit reflection, and then hit reflection again, which won&#x2019;t do anything. Then they get a very confused look on their face because their action had no immediate visual feedback!</p>
<p>I set up the installation so that the interface is mirrored on a large screen. Interaction takes on a performative quality. Visitors are always delighted to discover the live webcam feed and selfies ensue. The live webcam feed also subtly drives home the point that you&#x2019;re not constructing an image, you&#x2019;re constructing a <em>spatial transformation</em>&#x2014;the base image is arbitrary.</p>
<p><img src="refractorinstall1_large.jpg" class="FullScreenImage">
<img src="refractorinstall2_large.jpg" class="FullScreenImage"></p>
<p>Refractor was fun to play with, but I was disappointed that it could not be used to create arbitrary spatial transformations. I wanted a direct manipulation interface for shaders that was as mathematically expressive as typing GLSL code directly.</p>
<h2 id="first-prototype">First Prototype</h2>
<p>My first attempt took the &#x201C;series of transformations&#x201D; idea of Refractor and applied it to the simpler domain of one-dimensional functions, represented visually as a cartesian graph.</p>
<p>[Video showing sin with frequency, amplitude, offset]</p>
<h3 id="spreads">Spreads</h3>
<p>Some transformations take additional parameters, for example <code>+</code> and <code>*</code>. When you hover over a parameter, you see a &#x201C;spread&#x201D; showing how the resulting graph would change if you were to scrub that parameter.</p>
<p>[Video showing spreads and manipulation]</p>
<p>When you have a parameter of a function or of a program, you fundamentally need to understand how changing that parameter changes the result of the function. One way to do this is with good labels: give your variables good names. An additional technique is to make parameters scrubbable, so that you can conveniently <em>see</em> how changing the parameter changes the result with <em>continuous feedback</em>. This spread technique is yet another way to see how a parameter affects the result. It is even quicker than scrubbing, but is only useful when the spread can be effectively shown statically without being visually overwhelming.</p>
<p>A subtle design decision was that the spread shows the parameter values at discrete &#x201C;snap points&#x201D;, and they fade in and out depending on how close they are to the present parameter value. An earlier version had the spread lines move <em>with</em> the parameter, which was visually distracting.</p>
<p>[Two videos, showing discrete and moving with spreads]</p>
<h3 id="transclusion">Transclusion</h3>
<p>Parameters can be <em>transcluded</em> across multiple transformations. I think transclusion of values is more natural than referencing variables by name in direct manipulation interfaces. Bret Victor uses a similar technique in [Drawing Dynamic Visualizations].</p>
<p>[GFY showing transclusion]</p>
<p>An advantage of transclusion is that you never have reference errors. What was the name is now <em>just a label</em>. Like a comment. You can write anything here, and the label changes anywhere the shared value is used.</p>
<p>[GFY showing renaming]</p>
<p>Additionally, you can reuse a computed value anywhere that you can use a constant value. The &#x201C;drag to transclude&#x201D; gesture is consistent.</p>
<p>[GFY showing graph transclusion]</p>
<h2 id="second-prototype">Second Prototype</h2>
<p>The first prototype provided a single linear series of transformations&#x2014;data flow through a single, non-branching pipeline. Crude branching pipelines were hackable by transcluding computed values. My second prototype aimed to provide more natural support for branching data flow and also to implement functional (lambda) abstraction.</p>
<p>Additionally, there was activity around the lab about <a href="http://worrydream.com/ExplorableExplanations/">explorable explanations</a>, so I was interested in seeing if this type of interface could be used for interactive <a href="http://en.wikipedia.org/wiki/Literate_programming">literate programming</a>, source code that explains itself to its reader and provides opportunities to experiment with it in the context of reading.</p>
<h3 id="parameter-abstraction">Parameter Abstraction</h3>
<p>You make a function by first creating <em>a concrete example</em>, then specifying that a value should be <em>parameterized</em> by dragging it up into the function definition area.</p>
<div class="VideoEmbed" data-src="http://player.vimeo.com/video/112224393" data-aspect="0.696"></div>

<p>Start concrete, then generalize. This is the &#x201C;create by abstracting&#x201D; principle from Bret Victor&#x2019;s <a href="http://worrydream.com/LearnableProgramming/">Learnable Programming</a> essay.</p>
<p>By first creating a concrete example, all functions automatically get <em>default arguments</em>. Thus in the &#x201C;autocomplete&#x201D;, you can immediately see the effect of a function (with its default arguments). This is &#x201C;create by reacting&#x201D; from Learnable Programming.</p>
<h2 id="shadershop-proof-of-concept">Shadershop Proof of Concept</h2>
<p>Yoshiki Ohshima showed me an old eToys example about adding sine waves to produce a sawtooth wave and asked if we could try to produce it using the above prototype. I think we eventually got it but the interface didn&#x2019;t help.</p>
<p>I thought about how one would ideally build the sine waves example and came up with this:</p>
<div class="VideoEmbed" data-src="http://player.vimeo.com/video/92777770" data-aspect="1.294"></div>

<p>This is the moment everything came together. For me, the seed that grows these projects is an interactive prototype that demonstrates the <em>feeling</em> of a simple example. Once I capture the core feeling, everything else follows.</p>
<p>Often at the beginning of a project, what all the pieces are and how they&#x2019;ll all fit together is cloudy. The solution is to pick a specific example and then make just those pieces you need for the example and fit them together. Don&#x2019;t generalize, just get the basic example working! This can give a project its initial momentum.</p>
<h1 id="future-directions">Future Directions</h1>
<h1 id="development">Development</h1>
<h2 id="design-of-the-semantics">Design of the Semantics</h2>
<p>The semantics is the mathematics you are creating&#x2014;the type system. Often the hardest challenge is just <em>choosing good words</em> for the different concepts. Sometimes a diagrammatic notation is a helpful supplement.</p>
<p>For Shadershop, we have the notion of a <em>Function</em> which can either be a <em>Built in Function</em> (Line, Sine, Abs, etc.) or a <em>Compound Function</em>. A Compound Function consists of a combiner (Add, Multiply, Compose) and a list of <em>Child Functions</em>. A Child Function consists of a function and a <em>Transformation</em>. A <em>Defined Function</em> is a Compound Function whose combiner just takes the last child. Additionally a Defined Function has a label and is allowed to be used within multiple Compound Functions&#x2014;it can have multiple parents, so to speak.</p>
<p>[Image]</p>
<p>Sometimes the semantics is given. For example <a href="http://recursivedrawing.com/">Recursive Drawing</a> borrowed semantics without much modification from <a href="http://www.contextfreeart.org/">Context Free</a>. The earlier Shadershop prototypes were basic variations on GLSL. But things get more exciting, and much trickier, when the semantics coevolve with the affordances of the new interface.</p>
<h2 id="design-of-the-interface">Design of the Interface</h2>
<p>The interface is the surface that is presented and receives back from the human interacting with the system. Literally <em>the interface</em>. The nerve endings at the retina and the fingertips.</p>
<p>These are some questions that come up when I&#x2019;m thinking about interface design:</p>
<ul>
<li>How are the objects of the semantics <em>viewed</em>? There are often multiple views.</li>
<li>How are they manipulated?</li>
<li>How can implied objects be viewed? That is, if viewing the base objects of the semantics visualizes the <em>source code</em> of the program, how can you visualize the <em>run-time execution</em> of the program?</li>
<li>Can the run-time be manipulated? A good exercise is to ask &#x201C;what if I drag this?&#x201D; What <em>should</em> happen?</li>
<li>How are the views organized (layout)?</li>
<li>How can the programmer specify what she wants to be viewed? Where is the focus? Often this gets implemented as a selection or hover. Other times a view is created and then &#x201C;pinned&#x201D; to keep it open.</li>
</ul>
<p>Traditional programming only shows the source code of the program and the final result of the computation. Once you decide that actually <em>all</em> of the data that the computation produces is potentially visualizeable, the design challenge is to decide how and when to show it. When is it helpful and when does it distract? This can only be answered by understanding what the programmer is trying to do. So how can the programmer communicate this intent to the interface?</p>
<p>In Shadershop, the lines that are plotted on the main graph are determined by which functions are expanded in the outline.</p>
<p>[GFY showing outline expanding and collapsing]</p>
<p>Any function you see in the outline shows up on the main graph. An alternative design would be to have an additional toggle for each function, or perhaps a whole list of appearance settings for each function. I decided against this because showing and hiding needs to be fluid and because I wanted to strengthen the connection between the outline and the main graph.</p>
<p>Related, the pan and zoom of every thumbnail in the outline is the same as the pan and zoom of the main graph. You need this to make comparisons. Keep everything the same, except the differences that matter.</p>
<p>What to show and and what to hide? What are the differences that matter? And how do you give the programmer handles to control this? These questions are a huge part of the design process. Just to give an idea of the pitfalls, here&#x2019;s a shot of an abandoned prototype where so much was shown that all understanding was diluted.</p>
<p>[&#x201C;typer&#x201D; prototype shot]</p>
<h2 id="implementation-of-the-semantics">Implementation of the Semantics</h2>
<p>I generally represent a program as a data structure, in particular as a graph. I think the term of the art is <a href="http://en.wikipedia.org/wiki/Abstract_semantic_graph">Abstract Semantic Graph</a>.</p>
<p>When I&#x2019;ve talked to programmers who want to make new interfaces for programming, an impulse that often arises is to make a new text-based language first, and then make a new interface for manipulating the text-based representation. I think this is a mistake in that it distracts from the opportunities of direct manipulation interfaces, and you end up fiddling with parsers just to change your semantics. Better, in my opinion, is to start with a data structure representation of your &#x201C;source code&#x201D; and get right to work on the interpreter and interface!</p>
<p>Text-based languages get parsed into trees. Because trees can&#x2019;t have cycles, you generally need to refer to other nodes elsewhere in the tree indirectly, with some sort of name or identifier. I prefer to leapfrog this issue and just store my program as a graph rather than a tree. This representation makes it clear that a <em>name</em> is just a <em>label</em>, and you can change a name in one place and it changes everywhere, rather than making a dead link.</p>
<p>[Image showing graph representation]</p>
<p>It&#x2019;s well worth the time to make a way to serialize and deserialize the program representation! I do this with a <a href="#">naive object graph serializer</a> that creates a JSON representation. Any time I successfully render the interface I save the program representation to <code>localStorage</code>. So when I&#x2019;m working on a new feature or fixing a bug, I can refresh the browser but not have to rebuild the thing I&#x2019;m using to test the feature. I don&#x2019;t save when the interface fails to render, and this usually prevents the saved program representation from getting into an inconsistent state.</p>
<h2 id="implementation-of-the-interface">Implementation of the Interface</h2>
<p>The cartesian graphs and color maps are rendered with WebGL. I have a <a href="#">compiler</a> that takes any Function from my program representation and turns it into a string of GLSL code. It was fairly straightforward until I added in cacheing and other performance complications, for example making sure that any draggable parameter is sent to WebGL as a changing &#x201C;uniform&#x201D; value rather than as new GLSL code. It makes the code ugly, but dragging needs to feel smooth!</p>
<p>You can only have so many WebGL canvases on the page before the browser complains, so I cheat with one canvas overlayed full screen and then have a render step where I find rectangles that need to have something drawn and draw appropriately.</p>
<p>All the DOM is rendered with <a href="http://facebook.github.io/react/">React</a>. I don&#x2019;t use React&#x2019;s state at all, nor do I keep track of state-changing events. I just <a href="#">rerender after every mouse event</a>. I like this because I can think of rendering as a pure function from my program representation to HTML and I don&#x2019;t need to do any bookkeeping about what needs updating when. In the past I&#x2019;ve written this bookkeeping code, or used <a href="http://knockoutjs.com/">frameworks</a> that require different syntax for dealing with changing values versus immutable values, and it&#x2019;s such a distraction when I want to focus all my attention on exploring interface possibilities.</p>
<p>Interactive components are generally easy to express in React if they are self-contained. For example, to implement sliders or text fields, the pattern consists of passing in a <code>value</code> property as well as an <code>onChange(newValue)</code> callback which is responsible for doing whatever is necessary to make <code>value</code> equal to <code>newValue</code>. This <code>onChange</code> responsibility may be more or less involved, but the slider or text field is encapsulated from this logic.</p>
<p>However, it is tedious and sometimes challenging to implement interactions which are not self-contained. For example, dragging something from one panel to another requires global coordination. In particular, I felt that implementing the live reorderable outline view was harder than it needed to be.</p>
<p>[Reorderable Outline GFY]</p>
<p>Additionally, doing any kind of dynamic typography with editable text fields is a nightmare using current HTML <code>contenteditable</code> tools.</p>
<h2 id="graphic-design">Graphic Design</h2>
<p>I&#x2019;m not a great graphic designer but I think I get it good enough so that it doesn&#x2019;t distract.</p>
<p>The details need to help the eye organize the information without drawing attention away from the content. This implies using subtle colors&#x2014;only high enough contrast for the task, but no higher&#x2014;see for example the grid lines on the graph. The same goes for borders, shadows, and gradients. They&#x2019;re just there to help the eye parse the interface, in this case to distinguish between the &#x201C;content&#x201D; data and interface &#x201C;chrome&#x201D;.</p>
<p>I use a CSS preprocessor to let me use variables in my CSS. This is important to keep the spacing sizes, colors, etc. consistent. The eye is drawn to elements that <em>break</em> the pattern, so having inconsistent spacing will distract the eye unnecessarily.</p>
<p>It has helped me immensely to have my CSS auto-update without having to refresh the page so that I can tweak the styles with a much tighter feedback loop.</p>
<h2 id="bootstrapping">Bootstrapping</h2>
<p>The point of creating these interfaces is to tighten the feedback loop between the creator&#x2019;s mental model and the thing being created. Tighter both in terms of response time (continuous feedback versus turn-based feedback) and &#x201C;cognitive distance&#x201D; (spatial manipulation for spatial domains). Give the creator a direct connection to the work.</p>
<p>The computer&#x2019;s job is to support the creative process. Take care of all the tedious things so that the human creator can focus entirely on the creative act.</p>
<p>Similarly, it&#x2019;s important for us to live these values during the design and development of these interfaces.</p>
<p>We often do not <em>choose</em> our representations. We give up this choice and take what is <em>given</em> to us. For example, we think that to create a programming &#x201C;language&#x201D; we need to choose text.</p>
<h2 id="summary">Summary</h2>
<ul>
<li><p>Variables are shared values that are transcluded, not referenced by name.</p>
</li>
<li><p>Create functions by first creating a concrete example, then abstracting parameters out of the concrete example. An advantage of this is that you now naturally have default arguments for your function.</p>
</li>
</ul>
<p>Find ways to work more visually, rather than in symbol land:</p>
<p>Don&#x2019;t make a text-based language, start with an abstract data structure representation of the program so you don&#x2019;t get bogged down in parsing.</p>
<p>Tighten your feedback loops so that you&#x2019;re spending more time with the interface rather than with the code of the interface:</p>
<p>Serialize your program representation so refreshes don&#x2019;t destroy the world.</p>
<p>Set up auto-updating CSS.</p>
<p>Decouple the &#x201C;inner journey&#x201D; of programming from the surface-level activity. Then look for connections to other experiences. For example, Photoshop&#x2019;s visibility toggle [eye icon] is like &#x201C;commenting out&#x201D; a line of code.</p>
<p>Compositing layers</p>
<p>Reordering layers</p>
<p>Changing the opacity of an image layer is like scaling the range of a function.</p>
<p>Moving a layer is translating the domain.</p>
</div>

<div class="Footer">
<a href="/">Toby Schachman</a>
<a href="mailto:tqs@alum.mit.edu"><i class="icon ion-android-mail"></i> tqs@alum.mit.edu</a>
<a href="https://twitter.com/mandy3284"><i class="icon ion-social-twitter"></i> mandy3284</a>
</div>

<script src="/assets/page.js"></script>

</body>
</html>